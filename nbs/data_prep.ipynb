{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load, combine and delete original csv's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file names\n",
    "files = [\n",
    "    \"barcelona_weekdays.csv\", \"budapest_weekends.csv\", \"london_weekends.csv\", \"vienna_weekdays.csv\",\n",
    "    \"amsterdam_weekdays.csv\", \"barcelona_weekends.csv\", \"paris_weekdays.csv\", \"vienna_weekends.csv\",\n",
    "    \"amsterdam_weekends.csv\", \"berlin_weekdays.csv\", \"lisbon_weekdays.csv\", \"paris_weekends.csv\",\n",
    "    \"athens_weekdays.csv\", \"berlin_weekends.csv\", \"lisbon_weekends.csv\", \"rome_weekdays.csv\",\n",
    "    \"athens_weekends.csv\", \"budapest_weekdays.csv\", \"london_weekdays.csv\", \"rome_weekends.csv\"\n",
    "]\n",
    "\n",
    "# Directory containing files\n",
    "directory = \"../data/\"\n",
    "\n",
    "# Initialize an empty list to hold dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Read each file and append to the list\n",
    "for file in files:\n",
    "    # Create the full path to the file\n",
    "    file_path = os.path.join(directory, file)\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Add a column to identify the file (city and weekday/weekend)\n",
    "    city, period = file.replace('.csv', '').rsplit('_', 1)\n",
    "    df['city'] = city.capitalize()\n",
    "    df['period'] = period.capitalize()\n",
    "    # Append the dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Delete all the original files\n",
    "for file in files:\n",
    "    os.remove(os.path.join(directory, file))  # Delete each file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDP from wiki - United Nations estimate\n",
    "# https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)_per_capita\n",
    "gdp_mapping = {\n",
    "'Barcelona' : 30.058,       \n",
    "'Budapest'  : 18.728,   \n",
    "'London'    : 46.542,   \n",
    "'Vienna'    : 53.840,   \n",
    "'Amsterdam' : 57.871,       \n",
    "'Paris'     : 44.229,   \n",
    "'Berlin'    : 51.073,   \n",
    "'Lisbon'    : 24.651,   \n",
    "'Athens'    : 20.571,   \n",
    "'Rome'      : 37.150}\n",
    "\n",
    "# Apply the mapping to create a new 'GDP' column\n",
    "combined_df['GDP'] = combined_df['city'].map(gdp_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        30.058\n",
       "1        30.058\n",
       "2        30.058\n",
       "3        30.058\n",
       "4        30.058\n",
       "          ...  \n",
       "51702    37.150\n",
       "51703    37.150\n",
       "51704    37.150\n",
       "51705    37.150\n",
       "51706    37.150\n",
       "Name: GDP, Length: 51707, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GDP WEIRD?\n",
    "combined_df['GDP']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove very expensive rentals (1500 EUR pr night)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258 rows and 0.005% of the data removed\n"
     ]
    }
   ],
   "source": [
    "# filter out price over 1500\n",
    "data = combined_df[combined_df['realSum'] < 1500]\n",
    "\n",
    "# print message\n",
    "removed = combined_df.shape[0]-data.shape[0]\n",
    "percent = removed/combined_df.shape[0]\n",
    "print(f'{removed} rows and {round(percent,4)}% of the data removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        30.058\n",
       "1        30.058\n",
       "2        30.058\n",
       "3        30.058\n",
       "4        30.058\n",
       "          ...  \n",
       "51702    37.150\n",
       "51703    37.150\n",
       "51704    37.150\n",
       "51705    37.150\n",
       "51706    37.150\n",
       "Name: GDP, Length: 51449, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['GDP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'realSum',\n",
       " 'room_type',\n",
       " 'room_shared',\n",
       " 'room_private',\n",
       " 'person_capacity',\n",
       " 'host_is_superhost',\n",
       " 'multi',\n",
       " 'biz',\n",
       " 'cleanliness_rating',\n",
       " 'guest_satisfaction_overall',\n",
       " 'bedrooms',\n",
       " 'dist',\n",
       " 'metro_dist',\n",
       " 'attr_index',\n",
       " 'attr_index_norm',\n",
       " 'rest_index',\n",
       " 'rest_index_norm',\n",
       " 'lng',\n",
       " 'lat',\n",
       " 'city',\n",
       " 'period',\n",
       " 'GDP']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at all collumns\n",
    "list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Entire home/apt' 'Private room' 'Shared room']\n",
      "['Barcelona' 'Budapest' 'London' 'Vienna' 'Amsterdam' 'Paris' 'Berlin'\n",
      " 'Lisbon' 'Athens' 'Rome']\n",
      "['Weekdays' 'Weekends']\n"
     ]
    }
   ],
   "source": [
    "# Look at factor variables\n",
    "print(data['room_type'].unique())\n",
    "print(data['city'].unique())\n",
    "print(data['period'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by selecting only the chosen columns\n",
    "filtered_data = data[['room_type', 'person_capacity', 'biz', 'bedrooms', 'dist', 'metro_dist', 'city', 'period', 'attr_index', 'GDP']]\n",
    "\n",
    "# Apply one-hot encoding to the categorical columns 'room_type', 'city', and 'period'\n",
    "one_hot_encoded_data = pd.get_dummies(filtered_data, columns=['room_type', 'city', 'period'])\n",
    "\n",
    "# Convert all Boolean columns to integers (0 and 1)\n",
    "for col in one_hot_encoded_data.columns:\n",
    "    if one_hot_encoded_data[col].dtype == bool:\n",
    "        one_hot_encoded_data[col] = one_hot_encoded_data[col].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        30.058\n",
       "1        30.058\n",
       "2        30.058\n",
       "3        30.058\n",
       "4        30.058\n",
       "          ...  \n",
       "51702    37.150\n",
       "51703    37.150\n",
       "51704    37.150\n",
       "51705    37.150\n",
       "51706    37.150\n",
       "Name: GDP, Length: 51449, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GDP WEIRD?\n",
    "one_hot_encoded_data['GDP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "scaler_norm = MinMaxScaler()\n",
    "X_data_normalized = scaler_norm.fit_transform(one_hot_encoded_data)\n",
    "y_data_normalized = scaler_norm.fit_transform(data.loc[:, ['realSum']])\n",
    "\n",
    "X = X_data_normalized\n",
    "y = y_data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GDP WEIRD?\n",
    "len(np.unique(X[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15% saved for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# 15% of the remaining saved for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                  y_train,\n",
    "                                                  test_size=X_test.shape[0] / X_train.shape[0],  \n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "with open('../data/train_data.pkl', 'wb') as f:\n",
    "    pickle.dump((X_train, y_train), f)\n",
    "with open('../data/validation_data.pkl', 'wb') as f:\n",
    "    pickle.dump((X_val, y_val), f)\n",
    "with open('../data/test_data.pkl', 'wb') as f:\n",
    "    pickle.dump((X_test, y_test), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnb",
   "language": "python",
   "name": "airbnb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
